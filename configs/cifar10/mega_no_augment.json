{
    "model_params": {
      "name": "layered",
      "params": {
        "input_embedding_dim": 160,
        "output_embedding_dim": 160,
        "layers": [
          [ "transformer_encoder_layer", 
            { "d_model": 160, "nhead": 1, "dim_feedforward": 320, "dropout": 0.0, "attention_params":
            { "type": "ema", "v_dim_out": 320, "qk_dim_out": 96, "ema_dim": 16, "ema_kernel_size": 1025, "direction": "bidirectional" } } ],
          [ "transformer_encoder_layer", 
            { "d_model": 160, "nhead": 1, "dim_feedforward": 320, "dropout": 0.0, "attention_params":
            { "type": "ema", "v_dim_out": 320, "qk_dim_out": 96, "ema_dim": 16, "ema_kernel_size": 1025, "direction": "bidirectional" } } ],
          [ "transformer_encoder_layer", 
            { "d_model": 160, "nhead": 1, "dim_feedforward": 320, "dropout": 0.0, "attention_params":
            { "type": "ema", "v_dim_out": 320, "qk_dim_out": 96, "ema_dim": 16, "ema_kernel_size": 1025, "direction": "bidirectional" } } ],
          [ "transformer_encoder_layer", 
            { "d_model": 160, "nhead": 1, "dim_feedforward": 320, "dropout": 0.0, "attention_params":
            { "type": "ema", "v_dim_out": 320, "qk_dim_out": 96, "ema_dim": 16, "ema_kernel_size": 1025, "direction": "bidirectional" } } ],
          [ "transformer_encoder_layer", 
            { "d_model": 160, "nhead": 1, "dim_feedforward": 320, "dropout": 0.0, "attention_params":
            { "type": "ema", "v_dim_out": 320, "qk_dim_out": 96, "ema_dim": 16, "ema_kernel_size": 1025, "direction": "bidirectional" } } ],
          [ "transformer_encoder_layer", 
            { "d_model": 160, "nhead": 1, "dim_feedforward": 320, "dropout": 0.0, "attention_params":
            { "type": "ema", "v_dim_out": 320, "qk_dim_out": 96, "ema_dim": 16, "ema_kernel_size": 1025, "direction": "bidirectional" } } ],
          [ "transformer_encoder_layer", 
            { "d_model": 160, "nhead": 1, "dim_feedforward": 320, "dropout": 0.0, "attention_params":
            { "type": "ema", "v_dim_out": 320, "qk_dim_out": 96, "ema_dim": 16, "ema_kernel_size": 1025, "direction": "bidirectional" } } ],
          [ "transformer_encoder_layer", 
            { "d_model": 160, "nhead": 1, "dim_feedforward": 320, "dropout": 0.0, "attention_params":
            { "type": "ema", "v_dim_out": 320, "qk_dim_out": 96, "ema_dim": 16, "ema_kernel_size": 1025, "direction": "bidirectional" } } ]
        ]
      }
    },
    "head_params": {
      "ff_dim": 320,
      "num_hidden_layers": 0,
      "dropout_p": 0.0,
      "num_classes": 10,
      "reduction_method": "mean"
    },
    "data_module_params": {
      "name": "cifar10",
      "params": {
        "data_path": "datasets/cifar10",
        "max_len": 1025,
        "batch_size": 50,
        "pin_memory": true,
        "augment": false,
        "num_workers": 6
      }
    },
    "optimizer_params": {
      "lr": 1e-3,
      "betas": [ 0.9, 0.98 ],
      "weight_decay": 0.02
    },
    "trainer_params": {
      "max_epochs": 200,
      "gradient_clip_val": 1.0,
      "precision": "16-mixed",
      "enable_checkpointing": true,
      "default_root_dir": "out/cifar10/mega_no_augment",
      "accelerator": "gpu",
      "devices": [ 1 ]
    },
    "fit_params": { }
  }