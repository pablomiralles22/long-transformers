{
  "model_params": {
      "name": "layered",
      "params": {
          "input_embedding_dim": 128,
          "output_embedding_dim": 128,
          "layers": [
              [ "positional_embedding", { "mode": "learned", "max_seq_len": 1025, "embed_dim": 128 } ],
              [ "transformer_encoder_layer", 
                { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0, 
                    "attention_params": { "type": "positive", "qk_dim_out": 64 } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0, 
                    "attention_params": { "type": "positive", "qk_dim_out": 64 } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0, 
                    "attention_params": { "type": "positive", "qk_dim_out": 64 } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0, 
                    "attention_params": { "type": "positive", "qk_dim_out": 64 } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0, 
                    "attention_params": { "type": "positive", "qk_dim_out": 64 } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0, 
                    "attention_params": { "type": "positive", "qk_dim_out": 64 } } ]
          ]
      }
  },
  "head_params": {
      "ff_dim": 256,
      "num_hidden_layers": 0,
      "dropout_p": 0.0,
      "num_classes": 10,
      "reduction_method": "mean"
  },
  "data_module_params": {
      "name": "cifar10",
      "params": {
          "data_path": "datasets/cifar10",
          "max_len": 1025,
          "batch_size": 8,
          "pin_memory": true,
          "num_workers": 6,
          "augment": true
      }
  },
  "optimizer_params": {
      "lr": 0.001,
      "betas": [ 0.9, 0.98 ],
      "weight_decay": 0.01
  },
  "trainer_params": {
      "max_epochs": 200,
      "precision": "16-mixed",
      "enable_checkpointing": true,
      "default_root_dir": "out/cifar10/positive_transformer",
      "accelerator": "gpu",
      "devices": [ 2 ]
  },
  "fit_params": {
  }
}