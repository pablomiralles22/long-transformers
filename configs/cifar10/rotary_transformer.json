{
  "model_params": {
      "name": "layered",
      "params": {
          "input_embedding_dim": 160,
          "output_embedding_dim": 160,
          "layers": [
              [ "transformer_encoder_layer", 
                { "d_model": 160, "nhead": 8, "dim_feedforward": 320, "dropout": 0.0, 
                    "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 160, "nhead": 8, "dim_feedforward": 320, "dropout": 0.0, 
                    "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 160, "nhead": 8, "dim_feedforward": 320, "dropout": 0.0, 
                    "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 160, "nhead": 8, "dim_feedforward": 320, "dropout": 0.0, 
                    "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 160, "nhead": 8, "dim_feedforward": 320, "dropout": 0.0, 
                    "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
              [ "transformer_encoder_layer", 
                { "d_model": 160, "nhead": 8, "dim_feedforward": 320, "dropout": 0.0, 
                    "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ]
          ]
      }
  },
  "head_params": {
      "ff_dim": 256,
      "num_hidden_layers": 0,
      "dropout_p": 0.0,
      "num_classes": 10,
      "reduction_method": "mean"
  },
  "data_module_params": {
      "name": "cifar10",
      "params": {
          "data_path": "datasets/cifar10",
          "max_len": 1025,
          "batch_size": 32,
          "pin_memory": true,
          "num_workers": 6,
          "augmen": true
      }
  },
  "optimizer_params": {
      "lr": 0.001,
      "betas": [ 0.9, 0.99 ],
      "weight_decay": 0.04
  },
  "trainer_params": {
      "max_epochs": 200,
      "precision": "16-mixed",
      "enable_checkpointing": true,
      "default_root_dir": "out/cifar10/rotary_transformer_augmented",
      "accelerator": "gpu",
      "devices": [ 0 ]
  },
  "fit_params": {
    "ckpt_path": "out/cifar10/rotary_transformer_augmented/lightning_logs/version_8/checkpoints/epoch=72-val_acc=0.74.ckpt"
  }
}