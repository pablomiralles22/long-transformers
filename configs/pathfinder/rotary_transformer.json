{
    "model_params": {
        "name": "layered",
        "params": {
            "input_embedding_dim": 128,
            "output_embedding_dim": 128,
            "layers": [
                [ "positional_embedding", { "mode": "learned", "max_seq_len": 1025, "embed_dim": 128 } ],
                [ "transformer_encoder_layer", 
                  { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0,
                      "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
                [ "transformer_encoder_layer", 
                  { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0,
                      "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
                [ "transformer_encoder_layer", 
                  { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0,
                      "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
                [ "transformer_encoder_layer", 
                  { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0,
                      "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
                [ "transformer_encoder_layer", 
                  { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0,
                      "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ],
                [ "transformer_encoder_layer", 
                  { "d_model": 128, "nhead": 8, "dim_feedforward": 256, "dropout": 0.0,
                      "attention_params": { "type": "rotary", "freq": 10000, "learned_freq": false } } ]
            ]
        }
    },
    "head_params": {
        "ff_dim": 256,
        "num_hidden_layers": 0,
        "dropout_p": 0.0,
        "reduction_method": "mean"
    },
    "data_module_params": {
        "name": "pathfinder",
        "params": {
            "data_path": [ "datasets/lra_release/pathfinder32/curv_contour_length_14" ],
            "max_len": 1025,
            "batch_size": 64,
            "pin_memory": true,
            "enable_augment": true,
            "num_workers": 6
        }
    },
    "optimizer_params": {
        "lr": 0.001,
        "betas": [ 0.9, 0.999 ],
        "weight_decay": 0.01
    },
    "trainer_params": {
        "max_epochs": 200,
        "precision": "16-mixed",
        "enable_checkpointing": true,
        "default_root_dir": "out/pathfinder/rotary_transformer",
        "accelerator": "gpu",
        "devices": [ 0 ]
    },
    "fit_params": {
        "ckpt_path": "out/pathfinder/rotary_transformer/lightning_logs/version_15/checkpoints/epoch=146-val_acc=0.93.ckpt"
    }
  }