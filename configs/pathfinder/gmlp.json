{
    "model_params": {
        "name": "layered",
        "params": {
            "input_embedding_dim": 128,
            "output_embedding_dim": 128,
            "layers": [
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ],
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ],
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ],
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ],
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ],
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ],
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ],
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ],
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ],
                [ "gmlp", { "d_model": 128, "hidden_dim": 64, "seq_len": 1025, "dropout": 0.0, "mode": "conv", "num_kernels": 1 } ]
            ]
        }
    },
    "head_params": {
        "ff_dim": 256,
        "num_hidden_layers": 1,
        "dropout_p": 0.0,
        "reduction_method": "glu"
    },
    "data_module_params": {
        "name": "pathfinder",
        "params": {
            "data_path": "datasets/lra_release/pathfinder32/curv_contour_length_14",
            "max_len": 1025,
            "batch_size": 256,
            "pin_memory": true,
            "num_workers": 6
        }
    },
    "optimizer_params": {
        "lr": 0.001,
        "betas": [ 0.9, 0.98 ],
        "weight_decay": 0.0
    },
    "trainer_params": {
        "max_epochs": 80,
        "precision": "16-mixed",
        "enable_checkpointing": true,
        "default_root_dir": "out/pathfinder/gmlp",
        "accelerator": "gpu",
        "devices": [ 0 ]
    },
    "fit_params": { 
        "ckpt_path": "out/pathfinder/gmlp/lightning_logs/version_7/checkpoints/epoch=37-val_acc=0.79.ckpt"
    }
  }